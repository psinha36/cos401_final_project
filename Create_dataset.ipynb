{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Loading and/or creating new data sets"
      ],
      "metadata": {
        "id": "k-ZmDO52FWxX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N22BOxCAsQfD"
      },
      "outputs": [],
      "source": [
        "! pip --quiet install transformers datasets evaluate rouge_score torch bert_score py7zr"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Log into hugging face account to push data to account"
      ],
      "metadata": {
        "id": "TKaIYJDjE-hW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login, logout\n",
        "\n",
        "login(\"<access token>\", add_to_git_credential=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDkQg_dD7AuP",
        "outputId": "e24b6e67-f01b-4b37-850d-c4511af09773"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token is valid.\n",
            "Your token has been saved in your configured git credential helpers (store).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set the encoding "
      ],
      "metadata": {
        "id": "GC6vclRZFmiU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding"
      ],
      "metadata": {
        "id": "dpatnEvdjHfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload zipped summaries and correspondong texts"
      ],
      "metadata": {
        "id": "N7IspxSWKWOn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -u -q all_chapters.zip\n",
        "!unzip -u -q all_summaries.zip"
      ],
      "metadata": {
        "id": "DugmI0MMTyxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Matching text and summaries should have the same filename. Load the texts and labels into lists"
      ],
      "metadata": {
        "id": "KQEvihdOKaug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def get_text_and_summary(books, prefix = \"summarize: \"):\n",
        "  text_root = \"/content/all_chapters/\"\n",
        "  summary_root = \"/content/all_summaries/\"\n",
        "  texts = []\n",
        "  labels = []\n",
        "  for book in books:\n",
        "    print(book)\n",
        "    for filename in os.listdir(text_root + book):\n",
        "      text_path = f\"{text_root}{book}/{filename}\"\n",
        "      summary_path = f\"{summary_root}{book}/{filename}\" \n",
        "      if os.path.isfile(summary_path):\n",
        "        with open(text_root + book + \"/\" + filename) as text:\n",
        "          texts.append(prefix + text.read())\n",
        "        with open(summary_root + book + \"/\" + filename) as text:\n",
        "          labels.append(text.read())\n",
        "  return texts,labels"
      ],
      "metadata": {
        "id": "yVD6d45kc4xT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Choose a train/tezt split for the data, you can do it manually or just shuffle and split"
      ],
      "metadata": {
        "id": "I5rSYIteK__1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "# split: 332, 45\n",
        "old_books_train = ['adambede', 'alicesadventuresinwonderland', 'anneofgreengables','bleakhouse', 'candide', 'emma', 'thejungle', 'thepictureofdoriangray', 'theturnofthescrew']\n",
        "old_books_test = ['frankenstein', 'thehouseofthesevengables']\n",
        "\n",
        "# split: 205, 59\n",
        "new_books_train = ['catchingfire', 'dragontattoo', 'kiterunner', 'sisterhoodpants', 'thedavincicode', 'thefaultinourstars']\n",
        "new_books_test = ['readyplayerone', 'joyluckclub']"
      ],
      "metadata": {
        "id": "2CuIHFCRijJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Dataset objects from the data and push to hub"
      ],
      "metadata": {
        "id": "9Yv2cfKTLJDz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts, labels = get_text_and_summary(old_books_train)\n",
        "print(len(texts))\n",
        "print(len(labels))\n",
        "old_books_data_train = {'text': texts, 'summary': labels}\n",
        "old_books_data_train = Dataset.from_dict(old_books_data_train)\n",
        "old_books_data_train.push_to_hub(\"psin/old_books_data_train\", private=True)"
      ],
      "metadata": {
        "id": "FthmUWEEiW_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts, labels = get_text_and_summary(old_books_test)\n",
        "print(len(texts))\n",
        "print(len(labels))\n",
        "old_books_data_test = {'text': texts, 'summary': labels}\n",
        "old_books_data_test = Dataset.from_dict(old_books_data_test)\n",
        "old_books_data_test.push_to_hub(\"psin/old_books_data_test\", private=True)"
      ],
      "metadata": {
        "id": "LbriO_4ZiXwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts, labels = get_text_and_summary(new_books_train)\n",
        "print(len(texts))\n",
        "print(len(labels))\n",
        "new_books_data_train = {'text': texts, 'summary': labels}\n",
        "new_books_data_train = Dataset.from_dict(new_books_data_train)\n",
        "new_books_data_train.push_to_hub(\"psin/new_books_data_train\", private=True)"
      ],
      "metadata": {
        "id": "puwCB8CziYm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts, labels = get_text_and_summary(new_books_test)\n",
        "print(len(texts))\n",
        "print(len(labels))\n",
        "new_books_data_test = {'text': texts, 'summary': labels}\n",
        "new_books_data_test = Dataset.from_dict(new_books_data_test)\n",
        "new_books_data_test.push_to_hub(\"psin/new_books_data_test\", private=True)"
      ],
      "metadata": {
        "id": "dVOFqXm-iZTq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}